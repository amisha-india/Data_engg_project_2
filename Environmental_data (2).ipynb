{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMaUuShe9miKgZOzgRrbE+o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JrIlz7v6bUuP","executionInfo":{"status":"ok","timestamp":1726369923128,"user_tz":-330,"elapsed":50423,"user":{"displayName":"Sai Ganesh","userId":"17481651529590606089"}},"outputId":"8128f300-856d-4f3a-8972-c8b14193985f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=748db435b3f4c4bfc8d5ab9adf0247f846546f472dd182f666c703e450db7d06\n","  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.2\n"]}],"source":["pip install pyspark"]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","\n","# Create Spark session\n","spark = SparkSession.builder.appName(\"EnvironmentalData\").getOrCreate()\n"],"metadata":{"id":"yacrZ7hPcUpm","executionInfo":{"status":"ok","timestamp":1726369953501,"user_tz":-330,"elapsed":9299,"user":{"displayName":"Sai Ganesh","userId":"17481651529590606089"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["environment_stream = spark.read.option(\"header\", \"true\").csv(\"/content/environmental_data.csv\")\n"],"metadata":{"id":"zD2dB02XSblb","executionInfo":{"status":"ok","timestamp":1726369976363,"user_tz":-330,"elapsed":10873,"user":{"displayName":"Sai Ganesh","userId":"17481651529590606089"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["environment_stream = environment_stream.withColumn(\"PM25\", col(\"PM25\").cast(\"float\")) \\\n","    .withColumn(\"PM10\", col(\"PM10\").cast(\"float\")) \\\n","    .withColumn(\"CO2\", col(\"CO2\").cast(\"float\")) \\\n","    .withColumn(\"Temperature\", col(\"Temperature\").cast(\"float\")) \\\n","    .withColumn(\"Humidity\", col(\"Humidity\").cast(\"float\")) \\\n","    .withColumn(\"WindSpeed\", col(\"WindSpeed\").cast(\"float\"))"],"metadata":{"id":"1VqtUZVwSqQ2","executionInfo":{"status":"ok","timestamp":1726370091404,"user_tz":-330,"elapsed":463,"user":{"displayName":"Sai Ganesh","userId":"17481651529590606089"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Define threshold values for anomalies\n","PM25_THRESHOLD = 15.0\n","PM10_THRESHOLD = 20.0\n","CO2_THRESHOLD = 350.0\n","TEMP_THRESHOLD = 25.0\n","HUMIDITY_THRESHOLD = 50.0\n","WIND_THRESHOLD = 10.0\n","\n","# Function to detect anomalies\n","def detect_anomalies(df):\n","    return df.filter(\n","        (col(\"PM25\") > PM25_THRESHOLD) |\n","        (col(\"PM10\") > PM10_THRESHOLD) |\n","        (col(\"CO2\") > CO2_THRESHOLD) |\n","        (col(\"Temperature\") > TEMP_THRESHOLD) |\n","        (col(\"Humidity\") > HUMIDITY_THRESHOLD) |\n","        (col(\"WindSpeed\") > WIND_THRESHOLD)\n","    )\n","\n","# Apply anomaly detection to the streaming data\n","anomalies = detect_anomalies(environment_stream)\n","\n","anomalies.show()\n","\n","# save the anomalies detected to a new csv file\n","anomalies.write.mode(\"overwrite\").csv(\"detected_anomalies.csv\", header=True)\n","print(\"Detected Anomalies saved to new csv file\")"],"metadata":{"id":"y8NMGXP_9zTt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726370562966,"user_tz":-330,"elapsed":916,"user":{"displayName":"Sai Ganesh","userId":"17481651529590606089"}},"outputId":"86137414-fe2c-4f01-f885-c38ca59c5d4d"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------+-------------------+----+----+-----+-----------+--------+---------+\n","|SensorID|           DateTime|PM25|PM10|  CO2|Temperature|Humidity|WindSpeed|\n","+--------+-------------------+----+----+-----+-----------+--------+---------+\n","|       1|2024-09-01 08:00:00|12.5|18.3|400.0|       22.5|    60.0|     12.3|\n","|       1|2024-09-01 09:00:00|15.2|20.1|410.0|       23.1|    58.0|     11.7|\n","|       1|2024-09-01 10:00:00|13.0|19.5|405.0|       24.0|    57.0|     10.5|\n","|       2|2024-09-01 08:00:00|22.0|35.0|420.0|       25.0|    70.0|     14.8|\n","|       2|2024-09-01 09:00:00|23.5|36.5|430.0|       26.0|    69.0|     15.3|\n","|       2|2024-09-01 10:00:00|NULL|38.0|440.0|       27.0|    68.0|     15.0|\n","|       3|2024-09-01 08:00:00|18.5|25.0|395.0|       21.5|    55.0|      9.8|\n","|       3|2024-09-01 09:00:00|19.0|26.0|398.0|       22.0|    54.0|     10.2|\n","|       3|2024-09-01 10:00:00|17.8|25.5|400.0|       22.8|    53.0|     11.0|\n","+--------+-------------------+----+----+-----+-----------+--------+---------+\n","\n","Detected Anomalies saved to new csv file\n"]}]}]}